% !TEX root = thesis.tex
\chapter{Event and track selection}
\label{sec:selection}
The $\sqrtSnnE{5.02}$ $\pPb$ ($1.3 \cdot 10^{8}$ events, $\mathcal{L}_{\mathrm{int}} = \unit[62]{nb^{-1}}$) collisions were recorded in 2013 by the ALICE detector~\cite{aliceDetector}. The details of the performance of the ALICE detector during LHC Run~1 (2009-2013) are presented in ~\cite{alicePerformance}.

%For the 2010 $\pp$ collisions, the minimum bias (MB) triggered events are required to have at least one hit from a charged particle traversing the SPD or either side of the V0. 
%The pseudorapidity coverage of the SPD is $|\eta| < 2$ in the first layer and $|\eta| < 1.5$ in the second layer. %Combining this with the acceptance of the V0, the particles are detected in the range $-3.7 < \eta < 5.1$. The minimum %bias trigger definition 



%For the $\pp$ collisions, similar track cuts as in ~\cite{ALICE:2011ac} are used: at least two hits in the ITS are required, one of which needs to be in the three innermost layers, and 70 hits out of 159 are required in the TPC. In addition, the distance of the closest approach (DCA) of the track to the primary vertex is required to be smaller than $\unit{2}{cm}$ in the beam direction. In the transverse direction, a $\pt{}$ dependent cut DCA $< \unit{0.0105}{cm} + \unit{0.035}{cm} \cdot \pt{}^{-1.1}$ is used, where $\pt{}$ is measured in units of $\GeVc$. These track cuts are tuned to minimize the contamination from secondary particles.

%In $\pPb$ collisions the tracks are selected following the hybrid approach~\cite{hybridExplanation}. In this method tracks with at least one hit in the SPD and at least two hits in the whole ITS are always accepted. In addition, tracks with fewer than two hits in the ITS or no hits in the SPD are accepted, but only if an additional vertex constraint is fulfilled. In addition, the distance of the closest approach (DCA) of the track to the primary vertex is required to be smaller than $\unit{3.2}{cm}$ in the beam direction and smaller than $\unit{2.4}{cm}$ in the transverse direction. This approach is not affected by dead regions ins SPD. Thus it produces an azimuthal angle ($\varphi$) distribution that is as uniform as possible. The momentum resolutions of the two classes of particles are comparable up to $\pt{} \approx 10\;\GeVc$, but after that, tracks without ITS requirements have a worse resolution~\cite{alicePerformance,aliceBackgroundFluctuation}.




\section{Event selection}
This analysis uses both a minimum bias trigger and an EMCal based trigger to select the analysed events. 
%The V0 detector~\cite{forwarddetectorsTdr} provides the information for event triggering. The V0 detector consists of two scintillator hodoscopes that are located on either side of the interaction point along the beam direction. It covers the pseudorapidity region $-3.7 < \eta < -1.7$ (V0C) and $2.8 < \eta < 5.1$ (V0A).
 For the 2013 $\pPb$ collisions minimum bias events are required to have signals in both sides of V0, V0A (positive $\eta$, lead going side in $\pPb$ collisions) and V0C (negative $\eta$). The timing difference between the two stations is also used to reduce the contamination of the data sample from beam-gas events~\cite{alicePerformance}. 

EMCal is used to provide the jet trigger used in triggered datasets. EMCal can be used to trigger on single shower deposits or energy deposits integrated over a larger area. Latter case is used for jet triggers. The EMCal trigger definition in the 2013 $\pPb$ collisions requires an energy deposit of either \unit[10]{\gev}  for the low threshold trigger or \unit[20]{\gev} for the high threshold trigger in a $32\times32$ patch size. Triggers, V0 and EMCal are discussed in more detail in sections~\ref{sec:forward},~\ref{sec:trigger} and~\ref{sec:emcal}. 

\section{Track reconstruction}
%\setlength{\emergencystretch}{0em}

The analysis uses charged tracks that are reconstructed with the Time Projection Chamber (TPC)~\cite{aliceTPC} and the Inner Tracking System (ITS)~\cite{aliceITS}. These are discussed in sections~\ref{sec:tracking} and~\ref{sec:TPC}. A detailed overview of track reconstruction in ALICE can be found from~\cite{alicePerformance}. 

The track reconstruction procedure is shown in Figure~\ref{fig:tracking}. The figure shows only one track, but in reality the reconstruction has to deal with many tracks. The ALICE track reconstruction procedure starts in TPC. The TPC readout chambers include 159 tangential pad rows. The procedure starts from the outermost layer and based on proximity the hits in this layer are paired with hits in the next layer inwards. When this procedure reaches the innermost pad row in TPC, the algorithm proceeds to ITS using the information obtained from TPC as an initial seed. Similar procedure of pairing adjacent layers with a proximity cut is repeated in ITS.

When the reconstruction of tracks in ITS is completed, all reconstructed tracks are extrapolated to their point of closest approach to the interaction vertex obtained from SPD information. 
Then the track fitting is repeated but starting from the innermost layer and proceeding outwards. A Kalman filter~\cite{Fruhwirth:1987fm} technique is used to perform the new fits using the hits found in the previous stage. In this iteration the reconstructed tracks are matched also to other detectors in the central barrel beyond TPC. When this step is complete, a third and final refit step is performed, again proceeding from the outermost TPC pad rows inwards to the interaction point. This final refit provides the final track parameters. 

Using the reconstructed tracks the estimation of the primary vertex can be improved from the original SPD information. The reconstructed tracks are extrapolated to the beam line and the primary vertex position is determined by a weighted average of the points of closest approach.

The remaining step of the track reconstruction is the determination of secondary vertices. In this step the procedure selects all reconstructed tracks with distances of closest approach (DCA) to the primary vertex larger than a defined minimum value. %(?? \unit{mm} in \pPb). 
The algorithm determines points of closest approach for pairs of these tracks. If the tracks are close enough to each other and show properties of short lived particle decays, these points are identified as secondary vertices. 

\begin{figure}[h]
%\input{figures/tikz/tracking}
\includegraphics[width=0.9\textwidth]{figures/Schema-PcpTrackingALICE.png}
\caption{Principles of tracking in the ALICE experiment, showing the three successive paths allowing to build a track and refine its parameters. Numbers ranging from 1 to 10 mention the bits that are activated in case of success during the propagation of the Kalman filter at the considered stage. Figure from~\cite{Maire:1984041}.}
%CERN conditions, free to use
\label{fig:tracking}
\end{figure}

Combining the information from the ITS and the TPC provides a resolution ranging from $1$ to $10\,\%$ for charged particles with momenta from $0.15$ to $\unit[100]{\GeVc}$. For tracks without the ITS information, the momentum resolution is comparable to that of ITS+TPC tracks below transverse momentum $\pt{} = \unit[10]{\GeVc}$, but for higher momenta the resolution reaches $20\,\%$ at $\pt{} = \unit[50]{\GeVc}$~\cite{alicePerformance,aliceBackgroundFluctuation}. 


\subsection*{Track selection}
In $\pPb$ collisions the tracks are selected following the hybrid approach~\cite{hybridExplanation} which ensures a uniform distribution of tracks as a function of azimuthal angle ($\varphi$). The parameters in the approach are summarised in Table~\ref{tab:hybrid}. 

The first requirements are on the quality of the track fit in ITS and TPC. The ITS requirement only removes tracks that are clear outliers. For TPC the requirement is much more strict. For step 1 it is required that a track has 3 out of the 6 possible hits in ITS, one of which must be in the SPD. In step 2 this is replaced by a vertex constraint, which includes the primary vertex itself as a point to the track to improve the momentum resolution.

The approach requires that 70 out of the 159 possible pad rows in the TPC are crossed. This is a measure of the effective track length inside the TPC. This takes into account the possibility that a track can have missing pad rows if the charge in these clusters is below the detection threshold. Additionally the track selection criteria require that the ratio between crossed rows and geometrically possible clusters clusters is at least 0.8. This takes into account dead zones due to chamber boundaries and limited $\eta$-acceptance. For both steps the hybrid requires that the fraction of clusters shared with several tracks is less than 40\%.

%Additionally we only accept tracks with $\left| \eta \right| < 0.8$ to avoid border effects ot the TPC acceptance $\left| \eta \right| < 0.9$ 

Additional cuts are meant to ensure that the reconstructed tracks are actually produced in the primary collision. A particle might scatter in the detector altering its track. The particle after such a scatter is rejected in the cuts, as it no longer carries information about the primary collisions. The remaining cuts are on the DCA to primary vertex. To have confidence that the track comes from the primary collision, the track must be close enough to the primary vertex. The cuts are different for the distance along the beam axis ($\mathrm{DCA}_{z}$) and perpendicular to ($\mathrm{DCA}_{xy}$) the beam axis.


\begin{table}
\caption{Parameters in the hybrid track cut}
\label{tab:hybrid}
\begin{tabular}{c | c | c}
Track Cut & Step 1 & Step 2 \\
\hline
$\chi^2$ / ITS cluster & < 36 & < 36 \\
$\chi^2$ / ITS cluster & < 4 & < 4 \\
Hits in ITS & 3 & 0 \\
ITS hit requirements & 1 in SPD & No requirement \\
Vertex constraint & No & Yes \\
Number of crossed rows in TPC  & 70 & 70 \\
TPC crossed rows over findable clusters & > 0.8 & > 0.8 \\
Fraction of shared TPC clusters & < 0.4 & < 0.4 \\
Kink daughters & Rejected & Rejected \\
$\mathrm{DCA}_{xy}$ & < \unit[3.2]{cm} & < \unit[3.2]{cm} \\
$\mathrm{DCA}_{z}$ & < \unit[2.4]{cm} & < \unit[2.4]{cm} \\
Other & & Rejected by step 1 \\
\end{tabular}
\end{table}



%The momentum resolutions of the two classes of particles are comparable up to $\pt{} \approx 10\;\GeVc$, but after that, tracks without ITS requirements have a worse resolution~\cite{alicePerformance,aliceBackgroundFluctuation}.



%These detectors are located inside the large solenoidal magnet, that provides a homogeneous magnetic field of \unit[0.5]{T}. Tracks within a pseudorapidity range $|\eta| < 0.9$ over the full azimuth can be reconstructed. 

%The ITS is made up of the innermost Silicon Pixel Detector (SPD), the Silicon Drift Detector (SDD) and the outermost Silicon Strip Detector (SSD). Each of these consists of two layers. The TPC is a cylinder filled with gas. Gas is ionised along the path of charged particles. Liberated electrons drift towards the end plates of the cylinder where they are detected. 


\FloatBarrier
\section{Cluster selection}
Neutral particles used in jet reconstruction are reconstructed by the Electromagnetic Calorimeter (EMCal)~\cite{Cortese:2008zza}. The EMCal covers an area with a range of $|\eta| < 0.7$  in pseudorapidity and $ 100 \deg $ in azimuth. EMCal is complemented by the Dijet Calorimeter (DCal)~\cite{DCAL} and Photon Spectrometer (PHOS)~\cite{PHOS} that are situated opposite of the EMCal in azimuth. PHOS covers 70 degrees in azimuth and $\left| \eta \right| < 0.12$. The DCal is technologically identical to EMCal, but is located opposite to the EMCal. The DCal coverage spans 67 degrees in azimuth, but in pseudorapidity the mid region is occupied by the PHOS. Between the active volumes of PHOS and DCal, there is a gap of 10 cm.

\begin{table}[tb] 
\centering
\caption{Parameters used in the EMCal clusteriser}
\label{tab:clusters}
\begin{tabular}{| c | c |}
Setting & Value \\
Clusteriser seed & 0.2 \unit{\mev} \\
Clusteriser cutoff & 0.05 \unit{\mev} \\
Cells in cluster & > 1 \\
Track matching radius & 0.025 \\
Fiducial cut & 1 tower \\
Exotic cut & 0.97 \\
Minimal cluster Energy & 0.3 \unit{\gev}
%Maximum pair asymmetry & 0.8 \\
\end{tabular}
\end{table}

The clusters used in the analysis were obtained from the EMCal clusteriser. The parameters used in the clusteriser are summarised in Table~\ref{tab:clusters}. The clusteriser  searches for a tower with energy deposit greater than a defined seed energy and merges all towers that share a side if their energy deposit is higher than a defined threshold. In the next step all towers sharing a side with already included towers are added, again requiring that the energy deposits exceeds the threshold. The algorithm can identify local minima and halts the clustering in case that the neighbouring tower energy is higher. Already clustered towers are removed from the pool, so any individual tower can be clustered only once. 

Highly energetic calorimeter hits should spread into several towers as the electromagnetic shower evolves. However, some clusters with high energy have their energy located in a single tower. These are believed to come from a slow neutron hitting the APD readout of the towers. They are referred to as exotic clusters. The measure of exoticity is denoted as 
\begin{equation}
1 -\frac{E_\mathrm{cross}}{E_\mathrm{max}},
\end{equation}

\noindent where $E_\mathrm{max}$ is the energy in the most energetic tower and $E_\mathrm{cross}$ is the sum of the four towers neighbouring the most energetic one. The closer this is to 1, the more exotic the cluster is and the larger the probability that it is fake. Cut of 0.97 has been adopted as default for analyses using EMCal, including the one presented in this thesis. Any clusters above this cut are removed.

To suppress charged hadron contributions in EMCal, tracks identified by tracking detectors are extrapolated to the EMCal surface. The clusteriser looks for the closest cluster in EMCal and the track is further extrapolated until it reaches the same depth as the cluster. The remaining distance from the extrapolated track to the cluster is then checked to reject hadronic hits. Clusters matched to charged tracks are removed from the analysis as well as clusters being identified as fake. 








%The combination of charged tracks with  $\pt{} > \unit[0.15]{\GeVc}$ and neutral particles with $\pt{} > \unit[0.30]{\GeVc}$ is used to construct jets. 


%\subsection{statistics}
%Number of jets in different datasets and with different jet finders is shown in Table~\ref{tab:stats}. Background statistics for number of background cones (number of jets minus number of discarded cones) are shown in Table~\ref{tab:bgstats}. Ratio of background cones to number of jets is shown in Table~\ref{tab:bgratio}. The likelihood of having to discard a jet from background calculation is about 1-2\%.
%\begin{table}[h]
%\caption{Number of found jets by dataset and jet $\pt{}$ bin}
%\tiny
%\begin{tabular}{c | c | c | c | c | c | c | c | c | c}
%Jet $\pt{}$   &     5-10 & 10-20  & 20-30 & 30-40 & 40-60 & 60-80 & 80-100 & 100-150 & 150-500 \\
%MBFullR04 & 4969393 & 621753 & 32552 & 5584 & 1974 & 310 & 90 & 37 & 5 \\
%MBFullR05 & 4750567 & 826598 & 42373 & 5543 & 1719 & 276 & 73 & 29 & 3 \\
%MBChargedR04 & 3144538 & 673419 & 37783 & 4121 & 1009 & 148 & 36 & 12 & 1 \\
%MBChargedR05 & 2229247 & 175763 & 7961 & 1270 & 410 & 61 & 12 & 3 \\
%TriggeredFullR04 & 187557 & 115927 & 78138 & 51317 & 39262 & 8621 & 2409 & 1167 & 171 \\
%TriggeredFullR05 & 99991 & 77147 & 48612 & 34325 & 28104 & 6342 & 1726 & 794 & 104 \\
%TriggeredChargedR04 & 37411 & 29945 & 18186 & 13148 & 11142 & 2517 & 675 & 326 & 44 \\
%TriggeredChargedR05 & 433155 & 175031 & 54789 & 19776 & 10626 & 1983 & 457 & 194 & 15 \\
%\end{tabular}
%\label{tab:stats}
%\end{table}
%
%\begin{table}[h]
%\caption{Number of background cones used in perpendicular cone background calculation}
%\label{tab:bgstats}
%\tiny
%\begin{tabular}{c | c | c | c | c | c | c | c | c | c}
%Jet $\pt{}$     &   5-10 & 10-20  & 20-30 & 30-40 & 40-60 & 60-80 & 80-100 & 100-150 & 150-500 \\
%MBFullR04 & 4947583 & 617895 & 32357 & 5548 & 1965 & 310 & 90 & 37 & 5 \\
%MBFullR05 & 4710217 & 815461 & 41584 & 5439 & 1698 & 273 & 73 & 29 & 3 \\
%MBChargedR04 & 3117495 & 661106 & 36739 & 4014 & 988 & 144 & 36 & 12 & 1 \\
%MBChargedR05 & 2195286 & 172919 & 7860 & 1249 & 406 & 61 & 12 & 3 \\
%TriggeredFullR04 & 186574 & 115376 & 77949 & 51216 & 39196 & 8603 & 2405 & 1167 & 171 \\
%TriggeredFullR05 & 99102 & 76462 & 48320 & 34216 & 28038 & 6334 & 1722 & 794 & 103 \\
%TriggeredChargedR04 & 37160 & 29543 & 17988 & 13099 & 11129 & 2515 & 675 & 326 & 44 \\
%TriggeredChargedR05 & 313421 & 140707 & 45229 & 16243 & 8709 & 1604 & 377 & 154 & 14 \\
%\end{tabular}
%\end{table}
%
%\begin{table}[h]
%\caption{Ratio of background cone number to number of jets}
%\label{tab:bgratio}
%\tiny
%\begin{tabular}{c | c | c | c | c | c | c | c | c | c}
%MBFullR04 & 99.56\% & 99.38\% & 99.40\% & 99.36\% & 99.54\% & 100.00\% & 100.00\% & 100.00\% & 100.00\% \\
%MBFullR05 & 99.15\% & 98.65\% & 98.14\% & 98.12\% & 98.78\% & 98.91\% & 100.00\% & 100.00\% & 100.00\% \\
%MBChargedR04 & 99.14\% & 98.17\% & 97.24\% & 97.40\% & 97.92\% & 97.30\% & 100.00\% & 100.00\% & 100.00\% \\
%MBChargedR05 & 98.48\% & 98.38\% & 98.73\% & 98.35\% & 99.02\% & 100.00\% & 100.00\% & 100.00\% \\
%TriggeredFullR04 & 99.48\% & 99.52\% & 99.76\% & 99.80\% & 99.83\% & 99.79\% & 99.83\% & 100.00\% & 100.00\% \\
%TriggeredFullR05 & 99.11\% & 99.11\% & 99.40\% & 99.68\% & 99.77\% & 99.87\% & 99.77\% & 100.00\% & 99.04\% \\
%TriggeredChargedR04 & 99.33\% & 98.66\% & 98.91\% & 99.63\% & 99.88\% & 99.92\% & 100.00\% & 100.00\% & 100.00\% \\
%TriggeredChargedR05 & 72.36\% & 80.39\% & 82.55\% & 82.13\% & 81.96\% & 80.89\% & 82.49\% & 79.38\% & 93.33\% \\
%\end{tabular}
%\end{table}
%
%


\clearpage
\chapter{Analysis method}
\label{sec:methods}
\section{Jet Finding}
The analysis uses reconstructed jets as estimates of the original parton. Jet reconstruction essentially combines nearby tracks into jets. 

Collisions between hadrons are never as clean as electron-positron collisions. Even for a proton-proton collision there are participant partons, that will produce a soft background in addition to the hard scattering products. Jet reconstruction must deal with this soft background. The reconstruction is never perfect, one can have uncorrelated tracks that get included in the jet and some tracks originating from the parton are missed by the reconstruction. There are several methods to perform the reconstruction, all of which require some kind of size parameter, which cuts out jet participants too far from the jet axis. The tracks that are grouped into a jet are referred to as jet constituents. 

In each collision event, the jets are reconstructed using FastJet~\cite{fastjet} with the anti-$\kt{}$ algorithm~\cite{antikt}. Jets for R=0.4 are selected in $\left| \eta \right| < 0.25 $ to satisfy the fiducial acceptance of the EMCal. In jet reconstruction both charged tracks with $\pt{}>0.15\,\GeVc$ and neutral clusters with $\pt{}>0.30\,\GeVc$ are considered. Clusters that match charged tracks are removed before jet reconstruction. The analysis is then performed by analysing the charged jet constituents and results are presented in terms of the jet transverse momentum $\pt{,jet}$. 

\subsection{Anti \texorpdfstring{\kt{}}{kT} algorithm}
Jets are reconstructed using the anti-$\kt{}$ algorithm~\cite{antikt}. The algorithm works by trying to undo the splittings through combining protojets. First the algorithm creates a list of protojets. At the beginning the list is populated by converting each track in the event into a protojet. Then the algorithm proceeds by combining these protojets. A simplified picture of the process for a limited number of tracks is shown in Figure~\ref{fig:ktalg}

The algorithm calculates distance measures, $\kt{,i}$ and $\kt{,i,j}$ for each individual protojet and for each possible pair of protojets. For individual protojets this depends on the transverse momentum of the track.

\begin{equation}
\kt{,i}^2=\pt{,i}^{2p}
\end{equation}

\noindent For each pair of protojets the distance measure is calculated as

\begin{equation}
\kt{,i,j}^{2}=\min\left(\pt{,i}^{2p},\pt{,j}^{2p}\right)\frac{\Delta R^2_{i,j}}{D^2},
\end{equation}
\nopagebreak
\noindent where the distance is taken over azimuthal angle, $\phi$ and rapidity $y$, 
 \nopagebreak
 \begin{equation}
 \Delta R_{i,j}=\left(\phi_i-\phi_j\right)^2+\left(y_i-y_j\right)^2.
 \end{equation}

\noindent If $\kt{i}$ is the smallest quantity in the event then the protojet is promoted to a jet and it is removed from further consideration. If \kt{,i,j} is the smallest quantity the two protojets $i$ and $j$ are merged into a new protojet. This is repeated until no protojets are left.

The choice of the power $p$ in the distance measure depends on the algorithm used
\begin{itemize}
\item $p=1$:~$\kt{}$ algorithm
\item $p=0$:~Cambridge Aachen algorithm
\item $p=-1$:~anti-$\kt{}$ algorithm
\end{itemize}

With the choice $p=-1$ in anti-$\kt{}$ algorithm, the softest splittings are undone first. One consequence of the power choice in the anti-$\kt{}$ algorithm is that reconstructed jets have a shape close to circular.


   \begin{figure}
\centering
\includegraphics[width=0.8\textwidth]{figures/ktalg.pdf}
    \caption{A simple example of the antil-$\kt{}$ algorithm in progress. The red tracks in the leftmost figure are identified to have the smallest $k_{T,i}$ in the event and are combined into the red track of the middle figure. As this continues the remaining tracks are added to this or other jets. One tracks was deemed to be isolated enough to be counted as a protojet by itself. Note that the rightmost figure is zoomed out.}
    \label{fig:ktalg}
  \end{figure}






\section{Definition of \texorpdfstring{$\jt{}$}{jT} }
The reconstructed jet axis is used for $\jt{}$ reference. Any charged track within a fixed cone with radius $R$ is taken as a jet constituent, as opposed to using the constituent list provided by the jet algorithm. Anti-$\kt{}$ produces jets that are very circular in shape. Thus this doesn't change the constituent list considerably. Calorimeter clusters are used only in jet reconstruction.

The jet fragmentation transverse momentum, $\vec{\jt{}}$, is defined as the component of the constituent track momentum, $\vec{p}_{\mathrm{track}}$, transverse to the jet momentum, $\vec{p}_{\mathrm{jet}}$. It represents the transverse kick with respect to the initial hard parton momentum that a fragmenting particle receives during the fragmentation process, which is a measure of the momentum spread of the jet fragments.

   \begin{figure}
    \begin{center}
      \includegraphics[width = 0.60\textwidth]{figures/tikz/jtdef}
    \end{center}
    \caption{Illustration of $\vjt{}$. The jet fragmentation transverse momentum, $\vjt{}$, is defined as the momentum component of the track momentum, $\vec{p}_{\mathrm{track}}$, that is transverse to the jet momentum, $\vec{p}_{\mathrm{jet}}$.}
    \label{fig:jtdefinition}
  \end{figure}

The resulting $\vjt{}$ is illustrated in~\fig{fig:jtdefinition}. The length of the $\vjt{}$ vector depends on the jet and track momentum vectors $\vec{p}_\mathrm{jet}$ and $\vec{p}_\mathrm{track}$

  \begin{equation}
    \jt{} = \frac{|\vec{p}_{\mathrm{jet}} \times \vec{p}_{\mathrm{track}}|}{|\vec{p}_{\mathrm{jet}}|} \,.
  \label{eq:jtdefinition}
  \end{equation}


 
 
\noindent Resulting $\jt{}$ distributions are shown as 
\begin{equation}
\frac{1}{\jt{}}\frac{\mathrm{d}N}{\mathrm{d}\jt{}}
\end{equation}
distributions. The logic behind this is that $\jt{}$ is inherently a two-dimensional observable, comprised of $\jt{x}$ and $\jt{y}$ components. So the actual physical observable would be 
 
 \begin{equation}
 \frac{\mathrm{d}^2N}{\mathrm{d} \jt{x} \mathrm{d} \jt{y}}
 \end{equation}

\noindent Changing into polar coordinates with $\jt{r} = \jt{}$ and $\theta$ gives
 \begin{equation}
 \frac{\mathrm{d}^2N}{\jt{} \mathrm{d} \jt{} \mathrm{d} \theta},
 \end{equation}

\noindent where $\jt{}$ over the azimuth $\theta$ should stay constant and it can be integrated over, which gives 
\begin{equation}
\frac{1}{2\pi}\frac{\mathrm{d}N}{\jt{} \mathrm{d} \jt{}}.
 \end{equation}
 
Results of the raw inclusive $\jt{}$ distribution in four $\pt{,jet}$ bins with background are shown in Figure~\ref{fig:inclusive}. Background, i.e. the contribution from the underlying event, is further discussed in Section~\ref{sec:bg}
 
 \begin{figure}
\centering
\begin{subfigure}{0.95\textwidth}
\includegraphics[width=\textwidth]{results/MixedFullJetsR04JetConeJtInclusive.pdf}
%Tag 20170810 python2.7 Python/InclusiveWithBackground.py legotrain_CF_pPb-1053_20170223-2002_LHC13bcde.root
\end{subfigure}
\caption{Inclusive $\jt{}$ with background}
\label{fig:inclusive}
\end{figure}

 
\section{Unfolding detector effects}
The raw inclusive $\jt{}$ distributions are corrected for the detector inefficiency with an unfolding procedure. The procedure uses response matrices obtained from a \textsc{Pythia}~\cite{introPythia81} simulation.

Measured distributions are affected by two main factors; Limited acceptance - The probability to observe a given event is less than one and limited resolution - Quantity $x$ cannot be determined exactly, but there is a measurement error. True $f(x)$ and measured $g(y)$ distributions are connected by a convolution integral. Including statistical fluctuations this becomes
\begin{equation}
\hat g(y) = \int_a^b A\left(y,x\right) f(x) dx + \epsilon(y),
\end{equation}

\noindent where A is the detector response obtained by (for example) Monte Carlo simulations and $\epsilon(y)$ is the term coming from statistical fluctuations.
If $x$ and $y$~ are discrete variables we have
\begin{equation}
\hat g_i = \sum_{j=1}^m A_{ij}f_j+\epsilon_i,
\end{equation}

\noindent where $i$ and $j$ give the $\jt{}$ bins in the true and measured distributions. $f_j$ and $g_i$ give the counts in these bins.
\noindent Or in matrix form
\begin{equation}
\hat g = Af+\epsilon,
\end{equation}
\noindent where $\hat g$ and $f$ are vectors corresponding to the measured and true histograms. If the only detector effect is limited acceptance, $A$ is a diagonal matrix, i.e. $A_{ij}=0$ for $i\neq j$. We want to deduce the true distribution $f$, when the measured distribution $g$ is known. In a general discrete case the (naive) solution is obtained by the inverse matrix
\begin{equation}
\hat f = A^{-1}\hat g 
\end{equation}
However this usually leads to oscillating solutions and determining the inverse matrix can be difficult.

Two common methods to perform this inversion are Bayesian and SVD unfolding methods. Often the solution requires some additional {\emph{ a priori}} information. For example the solution should be smooth in most cases.

\subsection{Bayesian unfolding}
The bayesian (iterative) method is based on the Bayes formula~\cite{ADictionaryofStatistics}.
\begin{equation}
P\left(C_i |E_j\right)=\frac{P\left(E_j |C_i\right)P_0\left(C_i\right)}{\sum_{l=1}^{n_C}P\left(E_j |C_l\right)P_0\left(C_l\right)},
\end{equation}

\noindent i.e. the probability of Cause $C_i$ ("truth") given Effect $E_j$ ("observed"), $P\left(C_i |E_j\right)$, is proportional to the probability of observing $E_j$ given $C_i$, $P\left(E_j |C_i\right)$ (response matrix) and the true distribution $P_0\left(C_i\right)$. In the equation $l$ is a summation variable over the number of causes $n_C$.

In the unfolding procedure $P_0$ is given some starting distribution, either a uniform distribution or some guess of the final distribution. Taking into account the inefficiency this gives 

\begin{equation}
\hat n\left(C_i\right) = \frac{1}{\epsilon_i} \sum_{j=1}^{n_E}n\left(E_j\right)P\left(C_i | E_j\right),
\label{eq:bayes1}
\end{equation}
%\item First calculate $P\left(C_i |E_j\right)$ with the uniform distribution
\noindent where  $\epsilon_i$ is the efficiency (between 0 and 1) of getting any signal from Cause $C_i$, $P\left(C_i |E_j\right)$ is the conditional probability from Equation ~\ref{eq:bayes1}
%\begin{equation}
%P\left(C_i |E_j\right)=\frac{P\left(E_j |C_i\right)P_0\left(C_i\right)}{\sum_{l=1}^{n_C}P\left(E_j |C_l\right)P_0\left(C_l\right)},
%\end{equation}
and $n\left(E_j\right)$ are the observed frequencies. First  $P\left(C_i |E_j\right)$ is calculated with the uniform distribution or best guess of the shape of the distribution. This is then used to calculate the new distribution $\hat P\left(C_i\right)$
\begin{equation}
\hat N_{true} = \sum_{i=1}^{n_C} \hat n\left(C_i\right),\,\hat P\left(C_i\right) = P\left(C_i | n\left(E\right)\right) = \frac{\hat n\left(C_i\right)}{\hat N_{true}}
\label{eq:unfolded}
\end{equation}

\noindent $P_0$ is then replaced with $\hat P$ and the procedure is repeated until an acceptable solution is found. One way to gauge the acceptability is measuring the change between iterations. Initially there is a large change between iterations, but it should get small when close to the final distribution. The number of iterations should be as low as possible, as the errors increase when going further in the iterations, but the number of iterations must be high enough so that the correct distribution is extracted. 

The bayesian procedure alongside with the SVD unfolding method are implemented in the RooUnfold package~\cite{roounfold}, which is used to perform the unfolding in practice. SVD unfolding is another procedure that utilises the Singular Value Decomposition (SVD) of the response matrix to find the inverse of the response matrix~\cite{Hocker:1995kb}.
 
 \subsection*{Error propagation in the Bayesian procedure }
 The measured distribution has some statistical uncertainty, this should be reflected in the unfolded distribution. Additionally the response matrix may have some uncertainty if the statistics used in the Monte Carlo simulation were limited. 
 
For errors originating from the measured distribution RooUnfold uses the error propagation matrix 

\begin{equation}
\frac{\partial \hat n\left(C_i\right)}{\partial n\left(E_j\right)} = M_{ij} + \frac{\hat n\left(C_i\right)}{n_0\left(C_i\right)}\frac{\partial n_0\left(C_i\right) }{\partial n\left(E_j\right) } - \sum_{k=1}^{n_E}\sum_{l=1}^{n_C} \frac{n\left(E_k\right) \epsilon_l}{n_0\left(C_l\right)} M_{ik} M_{lk} \frac{\partial n_0 \left(C_l\right)}{\partial n\left(E_j\right)},
\end{equation} 
 
\noindent where $\hat n \left(C_i\right)$ is the unfolded result from Eq.~\ref{eq:unfolded}. This depends upon the matrix $\frac{\partial n_0\left(C_i\right)}{\partial n\left(E_j\right) }$, which is $\frac{\partial \hat n\left(C_i\right) }{\partial n\left(E_j\right) }$ from the previous iteration. In the first iteration, $\frac{\partial n_0\left(C_i\right) }{\partial n\left(E_j\right) }=0$ and $\frac{\partial \hat n\left(C_i\right) }{\partial n\left(E_j\right) } = M_{ij}$.
 
 The error propagation matrix $V$ is used to obtain the covariance matrix on the unfolded distribution 
 
 \begin{equation}
 V\left(\hat n\left(C_k\right), \hat n\left(C_l\right)\right) = \sum_{i,j=1}^{n_E} \frac{\partial \hat n\left(C_k\right) }{\partial n\left(E_i\right) }  V\left(\hat n\left(E_i\right), \hat n\left(E_j\right)\right)  \frac{\partial \hat n\left(C_l\right) }{\partial n\left(E_j\right) },
 \end{equation}
 
\noindent where $V\left(\hat n\left(E_i\right), \hat n\left(E_j\right)\right)$ is the covariance matrix of the measurements. In counting experiments common in particle physics, each bin is independently Poisson distributed, with
 
 \begin{equation}
 V\left(\hat n\left(E_i\right), \hat n\left(E_j\right)\right) = n\left(E_i\right) \delta_{ij}
 \end{equation}
 
 \noindent The error propagation matrix for the response matrix is 
 
 \begin{multline}
 \frac{\partial \hat n\left(C_i\right)}{\partial P \left(E_j| C_k\right)} = \frac{1}{\epsilon_i}\left(\frac{n_0 \left(C_i\right) n\left(E_j\right)}{f_j} - \hat n \left(C_i\right) \right) \delta_{ik} - \frac{n_0 \left(C_k\right) n\left(E_j\right)}{f_j} M_{ij} + \\
  \frac{\hat n\left(C_i\right)}{n_0\left(C_i\right)} \frac{\partial n_0\left(C_i\right)}{\partial P \left(E_j| C_k\right)} - \frac{\epsilon_i}{n_0\left(C_i\right)} \sum_{l=1}^{n_E}\sum_{r=1}^{n_C} n\left(E_l\right) M_{il} M_{rl} \frac{\partial n_0 \left(C_r \right)}{\partial P \left(E_j| C_k\right)},
 \label{eq:responseerror}
 \end{multline}
 
\noindent where $ \frac{\partial n_0\left(C_i\right)}{\partial P \left(E_j| C_k\right)}$ is the error propagation matrix from the previous iteration, $\frac{\hat n\left(C_i\right)}{\partial P \left(E_j| C_k\right)}$. For the first iteration, this is zero and the final two terms in Eq.~\ref{eq:responseerror} disappear.
 
 The covariance matrix due to these errors is given by
 
 \begin{equation}
 V\left(\hat n\left(C_k\right), \hat n\left(C_l\right)\right) = \sum_{j,s=1}^{n_E} \sum_{i,r=1}^{n_C} \frac{\partial \hat n\left(C_k\right) }{\partial P\left(E_j | C_i\right) }  V\left(P\left(E_j | C_i\right), P\left(E_s | C_r\right) \right)  \frac{\partial \hat n\left(C_l\right) }{\partial P\left(E_s | C_r\right) },
 \end{equation}
 
\noindent where $V\left(P\left(E_j | C_i\right), P\left(E_s | C_r\right) \right)$ can be taken as multinomial, Poisson or other distribution.
 
\subsection{Pseudo-experiment Monte Carlo} 
A Monte Carlo pseudo-experiment simulation was performed to see the performance of unfolding in an ideal case.
The simulation samples jet $\pt{}$ values from the observed $\pt{}$ distribution. Starting from this $\pt{}$ the simulation starts creating tracks with 
\begin{equation}
p_{\mathrm{track}} = z_\mathrm{track} \pt{,jet}
\end{equation}

\noindent where $z_\mathrm{track} $ is sampled from the observed $z$ distribution. Tracks are given random $\eta$ and $\phi$ values from uniform distributions centred at 0. All tracks below \unit[0.15]{\GeVc} are discarded. Sampling is continued until the sum of the track transverse momenta exceeds the jet transverse momentum. The sum of all the track momenta is calculate. This is sum is then defined to be the jet.

Simultaneously a $\pt{}$ dependant observation efficiency is applied to the tracks and a separate observed jet is calculated using only the observed tracks. Additionally a set of fake tracks is added to the observed jet. Fake tracks are generated identically to normal tracks, except for \pt{,track}, which is taken from a uniform distribution between \unit[0.15]{\GeVc} and \unit[1]{\GeVc}. Tracks are always either observed or not at the true momentum. No smearing is added to the observed momentum.

Afterwards the tracks are looped over for $\jt{}$ calculation. For observed tracks we calculate $\jt{}$ with respect to both the true jet axis and the observed jet. The two dimensional (2D) Response matrix is filled with \begin{equation}
\left(\jt{}^\mathrm{obs},\pt{,jet}^\mathrm{obs}, \jt{}^\mathrm{true},\pt{,jet}^\mathrm{true}\right),
\end{equation}

\noindent where $\jt{}^\mathrm{obs}$ and $\pt{,jet}^\mathrm{obs}$ are the observed values and $\jt{}^\mathrm{true}$ and $\pt{,jet}^\mathrm{true}$ are the true values. In practice this is done with a set of three dimensional (3D) histograms, where \pt{,jet,true} determines the histogram index and the remaining three values the bin in the 3D histogram.

After creating the response matrices, an identical procedure is carried out to the create testing data. Now instead of filling response matrices, 2D histograms are filled with $\left(\jt{}^\mathrm{obs},\pt{,jet}^\mathrm{obs}\right)$ and $\left(\jt{}^\mathrm{true},\pt{,jet}^\mathrm{true}\right)$

The observed distributions are unfolded using the 2D Bayesian (iterative) algorithm of RooUnfold. Results are shown in Figure~\ref{fig:toymc}. Aside from some discrepancy at very low \jt{} the true distribution is retrieved well. 

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{figures/analysis/ToyMCUnfolder_300k_events.pdf}
\caption{Results from unfolding in the pseudo-experiment Monte Carlo simulation}
\label{fig:toymc}
\end{figure}
\FloatBarrier






\subsection{Pythia Response matrices}
A \pythia~6 simulation was carried out to determine the response matrices.  The simulation used the Perugia 2011~\cite{pythiaPerugiaTune} tune with \snn=5.02\tev. The detector response of the particle level tracks was simulated using GEANT3~\cite{Brun:118715,geant}.

Response matrices are filled through correlation between MC detector and particle level jets and tracks. When creating the response matrices detector level tracks in each event are first analysed using the same procedure as for data, but their $\jt{}$ values are stored in an array. This is only done for tracks that are closer than the cone size, $R$, to a jet. Thus most tracks in the event will not have their $\jt{}$ values calculated. The analysis then moves to particle level (MC) tracks. There are analysed similarly, but for each track the code checks whether a corresponding detector level track existed and if that track had a \jt{} value. Finally the code checks for detector level tracks that don't have corresponding particle level track with a \jt{} value.

There are several possibilities that have to be taken into account:
\begin{itemize}
\item We find a corresponding track with a \jt{} value. Response matrix is filled normally with $\left(\jt{}^\mathrm{obs},\pt{,jet}^{obs},\jt{}^\mathrm{true},\pt{,jet}^{true}\right)$
\item We don't find a corresponding track. Record $\left(\jt{}^\mathrm{true},\pt{,jet}^\mathrm{true}\right)$ as a miss 
\item We find a corresponding track, but it didn't have $\jt{}$ value. Most likely because it was not part of a jet in the detector level set. Similary record $\left(\jt{}^\mathrm{true},\pt{,jet}^\mathrm{true}\right)$ as a miss
\item For detector level tracks that have no correspondence in particle level set the code records  $\left(\jt{}^\mathrm{obs},\pt{,jet}^\mathrm{obs}\right)$ as a fake
\end{itemize}

In the analysis code the response matrix is made of an array of 3 dimensional histograms, with $\left(\jt{}^\mathrm{obs},\pt{,jet}^\mathrm{obs},\jt{}^\mathrm{true}\right)$ as axes. The histogram index gives the $\pt{,jet}^\mathrm{true}$ value. The ranges in the response matrices of both $\jt{}$ and $\pt{,jet}$ match the ranges used for the end results. For \jt{} the range is between \unit[0.01]{\GeVc} and \unit[20]{\GeVc} and \pt{,jet} between \unit[5]{\GeVc} and \unit[500]{\GeVc}.  The ranges are the same in detector and particle level.

As a primary method unfolding is performed with an iterative (bayesian) algorithm using the RooUnfold~\cite{roounfold} package. The number of iterations used is 4.  As a default the true $\jt{}$ distribution from the \pythia~simulation is used as the prior.

%\begin{table}
%\centering
%\caption{$\jt{}$ and $\pt{}$ ranges used in unfolding. The same ranges are used for detector and truth level.}
%\label{tab:unfranges}
%\begin{tabular}{c | c | c}
% & $\jt{}$ & $\pt{,jet}$ \\
% \hline
%Min & 0.01 & 5 \\
%Max & 20 & 500 \\
%\hline
%\end{tabular}
%\end{table}

\subsection{Unfolding closure test}
The \pythia~set is divided into 2 halves. First is used to fill the response matrices, as well as record missed and fake tracks. Second half is used to test the effectiveness of the unfolding method. Jet $\pt{}$ distributions and response matrix are shown in Figure~\ref{fig:jetptclosure}. For the range where this analysis is performed, $\unit[40]{\GeVc} <\pt{,jet} <\unit[150]{\GeVc}$, the \pt{,jet} distribution is recovered well. At low \pt{,jet} the true distribution can't be recovered. The primary reason is that jet with $\pt{,obs}<\unit[5]{\GeVc}$ are not considered, although $\pt{,true}$ would have been above $\unit[5]{\GeVc}$. Thus these are missing from the response matrix and their contribution can't be unfolded. At high $\pt{,jet}$ the situation is opposite. Jets with $\pt{,true} > \unit[500]{\GeVc}$ are lost due to histogram limits. Thus jets just below this limit are overrepresented in the response matrix for $\pt{,obs}\approx \unit[500]{\GeVc}$. 
 
 \begin{figure}
\begin{subfigure}[b]{0.5\textwidth}
\includegraphics[width=0.7\textwidth]{figures/analysis/JetPtUnfolded.pdf}
%\caption{Unfolded jet $\pt{}$ distribution in \pythia~closure test}
%\label{fig:jetptunf}
\end{subfigure}
\begin{subfigure}[b]{0.5\textwidth}
\includegraphics[width=0.8\textwidth]{figures/analysis/JetPtResponse.pdf} 
%\caption{Jet $\pt{}$ response matrix from unfolding closure test}
%\label{fig:jetptresponse}
\end{subfigure}
\caption{\emph{left:} Unfolded jet $\pt{}$ distribution in \pythia~closure test \emph{right:} Jet $\pt{}$ response matrix from unfolding closure test}
\label{fig:jetptclosure}
\end{figure}
 
Response matrices within single jet $\pt{}$ bins are shown in Figure~\ref{fig:response}. Results from the closure test are shown in Figure~\ref{fig:closure}. In the lowest jet $\pt{}$ bins unfolding fails to recover the true distribution. The lowest jet $\pt{}$ bins are dominated by combinatorial jets and thus the true detector response is likely not retrieved.

Above $\unit[30]{\GeVc} <\pt{,jet} < \unit[40]{\GeVc}$~the distribution is recovered well in the mid $\jt{}$ region. At $\jt{} < \unit[0.1]{\GeVc}$ there is clear discrepancy and hence the final results are shown only for $\jt{} > \unit[0.1]{\GeVc}$. Additionally there is some discrepancy at very high $\jt{}$. This is taken into account in the unfolding systematics. %{\color{red}(TODO: Show this) }
\begin{figure}
\includegraphics[width=0.99\textwidth]{figures/analysis/ResponseMatrixNFin00.pdf}
\caption{$\jt{}$ Response matrices in individual $\pt{,jet}$ bins}
\label{fig:response}
\end{figure}

\begin{figure}
\includegraphics[width=0.99\textwidth]{figures/analysis/PythiaTest.pdf}
\includegraphics[width=0.99\textwidth]{figures/analysis/PythiaTest_Extra.pdf}
\caption{Pythia closure test results. Fake tracks include also tracks that do exist in the true dataset, but for one reason or another were not given $\jt{}$ values. $\jt{}$ is only calculated for tracks that are associated with jets.}
\label{fig:closure}
\end{figure}


\FloatBarrier


 
\section{Background}
\label{sec:bg}
When calculating \jt{} distributions for jet constituents there is a contribution from the underlying event (UE), i.e. tracks that just happen to be close to the jet axis.
To find the signal coming from the actual jet we need to subtract the background (UE) contribution. On a jet-by-jet basis this is difficult to achieve reliably, so one must estimate the background contribution in the inclusive  distribution. A schematic view of the background contribution is shown in Figure~\ref{fig:bgdef}. 

We have two methods for background estimation. In the first we look at the direction perpendicular to the jet. This is assumed to be the region least likely to contain jet contributions. In the second method we randomly assign the tracks of event new $\phi$ and $\eta$ values. The result is thus guaranteed to be uncorrelated.

\begin{figure}[h]
\centering
\begin{subfigure}{0.4\textwidth}
\input{figures/tikz/bgdef}
\caption{Orange is underlying event while gray tracks represent the signal}
\end{subfigure}
\begin{subfigure}{0.4\textwidth}
\input{figures/tikz/perpcone}

\caption{We estimate the background using a cone where the axis is perpendicular to the jet axis}
\end{subfigure}
\caption{Background estimation}
\label{fig:bgdef}
\end{figure}

\subsection{Perpendicular cone background}
As a primary method to estimate the background we look at regions of the detector where there are no tracks from jets, but only uncorrelated tracks from the underlying event. The underlying event is thus estimated by looking at an imaginary jet cone perpendicular to the observed jet axis ($\frac{\pi}{2}$ Rotation in azimuthal angle, $\phi$). 

%$\jt{}$ is calculated for any tracks found within this cone. The vector sum of the individual track momentum and the imaginary jet axis is used as reference for $\jt{}$. The background obtained in this manner is subtracted from the unfolded inclusive $\jt{}$ distribution, which gives the resulting signal distribution. To make sure there is no jet contribution in the background, any events with jets inside the perpendicular cone are not used for background estimation.

After calculating the $\jt{}$ values for tracks in the jet, we rotate the jet axis by $\frac{\pi}{2}$ in positive $\phi$ direction. We check that there are no other jets closer than $2R$ to the rotated axis. Otherwise background calculation is skipped for this jet. Probability of this happening is 1-2\% depending on the jet $\pt{}$ bin.

If we don't find other jets in the vicinity we move on to estimate the background. We find all tracks within a cone of radius $R$ around the rotated axis and calculate $\jt{}$ of these tracks with respect to the rotated axis. %Auto-correlations are discussed in Section~\ref{sec:autoC}. 

This background procedure is a part of the reason for using charged tracks inside a fixed size cone, instead of jet constituents. To be representative of the actual underlying event contribution the size and shape of the background estimation region should match the area where $\jt{}$ is calculated. The irregular shape of a jet would be hard to take into account when calculating background. Thus the regions are made to match by considering fixed size cones for $\jt{}$.






\begin{figure}[tb]
\centering
\input{figures/tikz/bgflow}
\caption{Flowchart representation of the perpendicular cone background procedure}
\label{fig:bgflow}
\end{figure}


One additional consideration is the issue of auto-correlations as the jet axis is simply a vector sum of all its constituents. Thus having an additional track in the jet from the underlying event moves the jet axis towards this track. Since the axis is now closer to the track, it has a smaller $\jt{}$ value. Assuming a \unit[1]{\GeVc} background track  at the edge of a $R = 0.4$ cone the $\jt{}$ value would be \unit[0.4]{\GeVc}. If this is added to a  \unit[5]{\GeVc} jet, the $\jt{}$ value becomes \unit[0.33]{\GeVc} after the jet axis moves. In a \unit[50]{\GeVc} jet it would be \unit[0.39]{\GeVc}. This is a region where the inclusive $\jt{}$ distribution is dominated by background. The distribution is also steeply falling. Overestimating the background can lead to a situation where the background estimation exceeds the inclusive distribution.

%\begin{figure}[htp]
%\centering
%\begin{subfigure}{0.99\textwidth}
%\includegraphics[width=0.95\textwidth]{figures/jt_in_jet_bg}
%\caption{Illustration of the effect of a track from the underlying event in a jet and for a fixed background axis}
%\end{subfigure}
%\begin{subfigure}{0.45\textwidth}
%\includegraphics[width=0.95\textwidth]{figures/jt_correction}
%\caption{Background behavior after adding auto-correlations}
%\end{subfigure}
%\caption{Auto-correlations in background and jets}
%\end{figure}

To take this effect into account we can't use a fixed axis for background, but it has to behave like a jet would when additional tracks are added. Thus before calculating $\jt{}$ values we make a vector sum of the track and the axis used for background, which is either the perpendicular cone axis or the random axis depending on the background method. In each case the momentum of this background axis is assumed to be the same as the jet which initiated the background estimation.

In \pPb data there is on average about one underlying event track in a $R = 0.4$ cone. If there would be more, one should consider taking the vector sum of all tracks inside the cone. As there is usually only one track and if there are more it's unlikely that more than one has high momentum, taking the vector sum track-by-track should be enough.








%\begin{figure}[htp]
%\centering
%\includegraphics[width=0.75\textwidth]{figures/jt_back}\\
%\end{figure}


%\begin{figure}[htp]
%\includegraphics[width=0.85\textwidth]{figures/2014-May-16-p-pb_jt_bgsub_060-080_0005-0100} \\
%\line(1,0){250}\\
%\raggedright
%\tiny{Král, Jiří, \textit{ Intrinsic Transverse Momentum Distribution of Jet
%Constituents in P-Pb Collisions at ALICE}, Ph.D. Thesis, University of Jyväskylä, 2014}
%%\item jT distribution is constructed from charged jet constituents
%\end{figure}

\subsection{Random background}
In the random background method we look at all tracks in the event, except for tracks close to jets found by the jet algorithm. We randomly assign new $\eta$ and $\phi$ values to all tracks using uniform distributions with $\left|\eta\right| < 1.0$. $\pt{}$ values are kept the same. To increase statistics there is a possibility to create a number of random tracks for each actual track. In the analysis we do this 10 times for each track. Again the track $\pt{}$ value is kept the same. 

We create a random jet cone from uniform $\eta$ and $\phi$ distributions. Here $\left| \eta \right| < 0.25$. Now we calculate $\jt{}$ of the random tracks with respect to the random cone axis. As in the perpendicular cone method auto-correlations are added before calculating \jt{}.

Comparison between perpendicular cone and random background in Figure~\ref{fig:bgcomparison}. The advantage of the random background method is that the procedure can be repeated several times for each event, which allows producing additional statistics. However, it seems that, especially in the highest $\pt{,jet}$ bins there is some jet contribution left at the high end. Naturally there is no correlation between the tracks and the background axis, but if some high momentum tracks originating from jets were not subtracted and happen to hit the edge of the background cone, they can increase the high $\jt{}$ yield in the background estimation.

\begin{figure}[htb]
\centering
\begin{subfigure}{0.95\textwidth}
\includegraphics[width=\textwidth]{results/MixedFullJetsR04BackgroundComparison.pdf}
%Tag 20170810 python2.7 Python/InclusiveWithBackground.py legotrain_CF_pPb-1053_20170223-2002_LHC13bcde.root
\end{subfigure}
\caption{$\jt{}$ background with two different methods}
\label{fig:bgcomparison}
\end{figure}

We observe that the results from perpendicular cone background show no observable change between $\pt{,jet}$ bins. It is a good indication that the background is actually dominated by the underlying event over the entire $\jt{}$ region. 

Thus as a primary method of background estimation the perpendicular cone method is used. The random background method is used to estimate systematic contributions by comparing the final results obtained with this method to the results obtained from the perpendicular cone method.


\FloatBarrier
 \section{Fitting}
 \label{sec:fitting}
After unfolding and background subtraction the resulting signal distributions are fitted with a 2 component function shown in Eq.~\ref{eq:fit}. Gaussian distribution is used for low $\jt{}$ and an inverse gamma function is used for high $\jt{}$. The Gaussian is taken to have the centre at $\jt{} = 0$. In total this gives 5 parameters. The fitting procedure was inspired by the dihadron $\jt{}$ analysis by ALICE~\cite{ALICEjt}. The complete fitting function is 

\begin{equation}
\frac{1}{N_{\mathrm{jets}}}\frac{\mathrm{d}N}{\jt{} \mathrm{d}\jt{}} = \frac{B_2}{B_1\sqrt{2\pi}}e^{-\frac{\jt{}^2}{2B_1^2}}+\frac{B_3B_5^{B_4}}{\Gamma\left(B_4\right)}\frac{e^{-\frac{B_5}{\jt{}}}}{\jt{}^{B_4+1}},
\label{eq:fit}
\end{equation}

\noindent where $\Gamma\left(x\right)$ is the gamma function and $B_n$ are parameters of the fit.

To achieve stable results the fitting is performed in two steps. First both components are fitted separately. Gaussian component is fitted to the low end of $\jt{}$. Inverse gamma component is fitted to $\jt{}$ above $\unit[1]{\GeVc}$. After getting the results from the individual fits they are combined into a single function with initial values from the individual results and an additional fit is performed. 
%Fitting only the Gaussian component to the entire distribution produces approximately the same result as the Gaussian component in the two-component model.

After getting the fit function $\sqrt{\left<\jt{}^2\right>}$ (RMS) and yield values are extracted separately from each component. The narrow component RMS is

\begin{equation}
\sqrt{\left<\jt{}^2\right>}=\sqrt{2}B_1,
\end{equation}


\noindent and the wide component RMS value is calculated as 

\begin{equation}
\sqrt{\left<\jt{}^2\right>}=\frac{B_5}{\sqrt{\left(B_4-2\right)\left(B_4-3\right)}},
\end{equation}


\noindent where it is required that $B_4 > 3$.

The statistical errors can be calculated with the general error propagation formulas. As a result one gets errors for the narrow component RMS
\nobreak
\begin{equation}
\delta \sqrt{\left<\jt{}^2\right>} = \sqrt{2}\delta B_1
\end{equation}
\noindent and for the wide component RMS

\begin{equation}
\delta \sqrt{\left<\jt{}^2\right>} = \sqrt{ \left( \frac{\left(5-2 B_4 \right) B_5 \delta  B_4}{\left( 2\left(  B_4-2\right)\left( B_4-3\right)      \right)^{\frac{3}{2}}}\right)^2 + \left( \frac{\delta B_5}{\sqrt{\left( B_4-2\right)\left( B_4-3\right)}}      \right)^2  }.
\end{equation}

%Yield(narrow)
%$$\frac{\delta Y}{N_{\mathrm{jet}}} = \sqrt{\frac{B_2^2\delta B_1^2+B_1^2\delta B_2^2}{2\pi}}$$
% Yield(Wide)
% $$ \frac{\delta Y}{N_{\mathrm{jet}}} = \sqrt{\left(\frac{B_5\delta B_3}{B_4-1} \right)^2+ \left(\frac{B_3B_5\delta B_4}{\left(B_4-1 \right)^2} \right)^2 + \left(\frac{B_3 \delta B_5}{B_4-1}\right)^2}$$


